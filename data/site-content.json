{
  "sidebar": {
    "avatar": {
      "src": "data/display_picture.jpg",
      "alt": "Profile photo"
    },
    "name": "Sri Surya S. Vaddhiparthy",
    "headline_lines": [
      "Senior Data Engineer",
      "• ETL/ELT • Python • SQL • Airflow • AWS • Snowflake • Kafka • dbt"
    ],
    "degree_lines": [
      "Master of Science in Data Science",
      "Western Michigan University"
    ],
    "location": "United States",
    "employer": "Comerica Bank (via Collaborate)",
    "nav": {
      "main": [
        {
          "href": "#summary",
          "label": "Professional Summary"
        },
        {
          "href": "#research-interests",
          "label": "Skill Set"
        },
        {
          "href": "#projects",
          "label": "Projects"
        },
        {
          "href": "#contact",
          "label": "Contact"
        }
      ],
      "profiles": [
        {
          "type": "linkedin",
          "chip": "in",
          "label": "LinkedIn",
          "href": "https://www.linkedin.com/in/vaddhiparthy/"
        },
        {
          "type": "github",
          "chip": "gh",
          "label": "GitHub",
          "href": "https://github.com/Vaddhiparthy/"
        },
        {
          "type": "email",
          "chip": "@",
          "label": "Email",
          "href": "mailto:surya@vaddhiparthy.com"
        }
      ]
    }
  },
  "topbar": {
    "name": "Sri Surya S. Vaddhiparthy",
    "subtitle": "Senior Data Engineer"
  },
  "sections": {
    "summary": {
      "title": "Professional Summary",
      "paragraphs": [
        "I am a Senior Data Engineer with eight years of experience designing, building, and operating large-scale data platforms that power analytics and decision-making. My work focuses on turning complex, multi-source data into reliable, governed systems that teams can trust, with measurable improvements in performance, quality, and cost.",
		"I specialize in end-to-end data engineering across batch and streaming systems, with deep experience in Python, SQL, Airflow, AWS, Snowflake, dbt, Kafka, and Spark. I have led initiatives that improved time-to-insight by approximately 42 percent, increased query performance by nearly three times, reduced data incident resolution time by 35 percent, and lowered warehouse compute costs by around 20 percent through disciplined FinOps and optimization practices.",
		"My approach emphasizes strong engineering fundamentals: automated testing and validation, monitoring and observability, CI/CD and infrastructure-as-code, and reusable pipeline patterns that make data platforms easier to scale and maintain. I work closely with analytics and business stakeholders to establish clear data models, consistent KPI definitions, and semantic layers that prevent metric drift and accelerate confident decision-making.",
		"I am driven by building data systems that are not only fast and scalable, but also dependable, cost-efficient, and easy for organizations to grow on."	
      ]
    },
    "research_interests": {
      "title": "Data Engineering Skill Set",
      "items": [
        "Core Data Engineering: Python, SQL; ELT/ETL pipelines, reusable ingestion patterns, incremental loads, backfills, auditability.",
        "Modeling & Analytics: Dimensional modeling (Star/Snowflake schema), curated marts, governed metrics, semantic layers.",
        "Orchestration & Transformation: Airflow, dbt (models/macros/tests/docs), DAG scheduling, dependency management, reliability patterns.",
        "Streaming & Distributed Compute: Kafka, Spark, PySpark (Batch + Streaming fundamentals).",
        "Cloud & Warehousing: Snowflake; AWS (S3, Glue, Lambda, ECS/Fargate, Redshift); Databricks/Delta Lake.",
        "Quality & Observability: Great Expectations, Monte Carlo; SLAs, lineage, monitoring, incident runbooks.",
        "BI & Semantics: Power BI, Tableau; KPI design and governance.",
        "Dev & Automation: Git, CI/CD, Docker, Terraform; testing, code review, repeatable deployments.",
		"AI Engineering: Prompt design, RAG fundamentals (LangChain/LangGraph), Vector Databases (pgvector/Milvus), LLM evaluation."
      ]
    },
    "projects": {
      "title": "Selected R&D & Engineering Projects",
      "items": [
        {
          "title": "Secure PII Event Ingestion Framework (SQS → Postgres)",
          "url": "https://github.com/vaddhiparthy/Login-Events-ETL",
          "description": "Built a decoupled pipeline using AWS SQS (via LocalStack) and Python. Implemented SHA-256 pseudonymization for PII fields during the ingestion flight.",
          "tech_stack": "Python, boto3, psycopg2, PostgreSQL, Docker"
        },				
        {
          "title": "LLM Integration Gateway & Context Orchestrator (Deployed on Current Page)",
          "url": "",
          "description": "Engineered a containerized FastAPI backend to bridge public frontend interfaces with OpenAI’s orchestration layer. Designed a decoupled architecture to secure API credentials and implement custom context-injection, ensuring responses are grounded in curated datasets while enforcing strict Pydantic schema validation and CORS security.",
          "tech_stack": "Python, FastAPI, Uvicorn, Pydantic, OpenAI SDK, Render, Docker."
        },
        {
          "title": "ASTRA-X Overthinker: Agentic Workflow Orchestrator",
          "url": "https://github.com/vaddhiparthy/ASTRA-X-Overthinker-v2",
          "description": "Created a workflow engine that automates scheduled iterations and persists goal states. It generates timestamped progress logs and human-readable changelogs for reproducibility.",      
		  "tech_stack": "Python, Flask, APScheduler, YAML, Ollama."
        },
		{
          "title": "VideoSemanticAlignment: Multimodal Fine-Tuning Pipeline & Research - Manuscript draft in progress.",
          "url": "",
          "description": "Data Architect for a vision-language research project. Engineered a high-throughput preprocessing workflow that cleans event-level text and aligns it to specific video temporal segments. Built the underlying data infrastructure to generate high-fidelity supervised pairs for multimodal fine-tuning, directly enabling state-of-the-art narrative-to-visual mapping.",      
		  "tech_stack": "Python, Vision–Language Models (VLM), PyTorch, Temporal Data Alignment, Dataset Distillation."
        }		
      ]
    },
    "contact": {
      "title": "Contact",
      "email": "surya@vaddhiparthy.com",
      "linkedin_url": "https://www.linkedin.com/in/vaddhiparthy/",
      "cal_url": "https://cal.com/vaddhiparthy/15min"
    }
  },
  "footer": {
    "text": "© Sri Surya S. Vaddhiparthy. All rights reserved."
  }
}
